{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUgS3TeRSs0u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francisdamachi/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/francisdamachi/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import keras\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version with timedistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcLk8_-iAX6e"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate(model, start= 1, length_generate = 7) :\n",
    "    print(reversed_dictionary[start])\n",
    "    start_word = start\n",
    "    built_phrase = [start_word]\n",
    "\n",
    "    seed_text = np.array([start_word])\n",
    "    seed_text = pad_sequences([seed_text],maxlen=7, padding='post')\n",
    "    predictions = model.predict_classes(seed_text, verbose=0)\n",
    "\n",
    "\n",
    "    for i in range(length_generate): \n",
    "      predict = predictions[0][i]\n",
    "      built_phrase.append(predict)\n",
    "      seed_text = pad_sequences([built_phrase], maxlen=7, padding=\"post\")\n",
    "      predictions = model.predict_classes(seed_text, verbose =0)\n",
    "\n",
    "    return built_phrase\n",
    "def read_words(filename):\n",
    "    with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "        return f.read().decode(\"utf-8\").replace(\"\\n\", \"eos\").split()\n",
    "      \n",
    "def build_vocab(filename):\n",
    "    data = read_words(filename)\n",
    "\n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(1,len(words)+1)))\n",
    "\n",
    "    return word_to_id\n",
    "  \n",
    "  \n",
    "def file_to_word_ids(filename, word_to_id):\n",
    "    data = read_words(filename)\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]\n",
    "  \n",
    "  \n",
    "def load_data(file):\n",
    "    # get the data paths\n",
    "    train_path = os.path.join(data_path,file)\n",
    "    # build the complete vocabulary, then convert text data to list of integers\n",
    "    word_to_id = build_vocab(train_path)\n",
    "    train_data = file_to_word_ids(train_path, word_to_id)\n",
    "    \n",
    "    vocabulary = len(word_to_id)\n",
    "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "\n",
    "    print(train_data[:5])\n",
    "    print(word_to_id)\n",
    "    print(vocabulary)\n",
    "    print(\" \".join([reversed_dictionary[x] for x in train_data[:10]]))\n",
    "    return train_data, vocabulary, reversed_dictionary\n",
    "  \n",
    "  \n",
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary+1\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "        # skip_step is the number of words which will be skipped before the next\n",
    "        # batch is skimmed from the data set\n",
    "        self.skip_step = skip_step\n",
    "\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "        x = np.zeros((self.batch_size, self.num_steps))\n",
    "        y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    # reset the index back to the start of the data set\n",
    "                    self.current_idx = 0\n",
    "                data_tmp = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                x[i, :] = data_tmp\n",
    "                temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
    "                # convert all of temp_y into a one hot representation\n",
    "                y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
    "                \n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "150_E92DZqD3",
    "outputId": "c3473d14-a87e-4354-a6a9-bb303101a575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 5, 23, 21]\n",
      "{'pail': 17, 'jill': 5, 'jack': 4, 'went': 23, 'fell': 12, 'of': 16, 'came': 10, 'down': 3, 'broke': 9, 'the': 18, 'hill': 14, 'to': 19, 'water': 22, 'fetch': 13, 'up': 21, 'after': 7, 'crown': 11, 'tumbling': 20, 'his': 15, 'big': 8, 'eos': 1, 'a': 6, 'and': 2}\n",
      "23\n",
      "jack and jill went up the hill eos to fetch\n"
     ]
    }
   ],
   "source": [
    "data_path = './'\n",
    "num_steps = 7\n",
    "batch_size = 1\n",
    "skip_step = num_steps + 1\n",
    "hidden_size = 50\n",
    "num_epochs = 500\n",
    "input_shape = num_steps\n",
    "\n",
    "\n",
    "train_data, vocabulary, reversed_dictionary = load_data('data.txt')\n",
    "train_data_generator = KerasBatchGenerator(train_data, num_steps, batch_size, vocabulary,\n",
    "                                           skip_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "i_3ne4mBu_qf",
    "outputId": "7f2e8da8-72cc-427f-c29c-5e766ddf78a2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee41f42d9a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary+1, 10, input_length=num_steps))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocabulary+1)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit_generator(train_data_generator.generate(),len(train_data)//(batch_size* num_steps),epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id  = dict([(v,k) for k,v in reversed_dictionary.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3X45jlXSE9FL",
    "outputId": "449a5783-5685-4777-cc7e-5c5781daa25c"
   },
   "outputs": [],
   "source": [
    "#text = generate(model,20)\n",
    "\n",
    "# = sad, anger, anx, negemo, posemo\n",
    "\n",
    "import keras\n",
    "\n",
    "def generate(model, start= 'jack', length_generate = 7) :\n",
    "    \n",
    "    start_ = start.split(\" \")\n",
    "    start = [word2id[w] for w in start_]\n",
    "    start_word = start\n",
    "    built_phrase = start_word\n",
    "\n",
    "    seed_text = np.array(start_word)\n",
    "    seed_text = keras.preprocessing.sequence.pad_sequences([seed_text],maxlen=7, padding='post')\n",
    "    \n",
    "\n",
    "    predictions = model.predict_classes(seed_text, verbose=0)\n",
    "    \n",
    "    for i in range(length_generate): \n",
    "      predict = predictions[0][i]\n",
    "      built_phrase.append(predict)\n",
    "     \n",
    "      seed_text = keras.preprocessing.sequence.pad_sequences([built_phrase], maxlen=length_generate, padding=\"post\")\n",
    "      predictions = model.predict_classes(seed_text, verbose =0)\n",
    "\n",
    "    return [reversed_dictionary[w] for w in built_phrase]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jack', 'up', 'and', 'jill', 'went', 'up', 'the', 'hill', 'eos']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model,'jack up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "version1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
