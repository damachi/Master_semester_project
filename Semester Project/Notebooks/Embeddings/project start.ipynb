{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a word embedding from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/cornell movie-dialogs corpus/movie_lines.txt',encoding='utf-8', errors ='ignore') as file:\n",
    "    data = file.readlines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = []\n",
    "for line in data :\n",
    "    split_string = line.split('+++$+++')\n",
    "    dict_values = {'movieID':split_string[2], 'character name':split_string[3], 'utterance': split_string[4]}\n",
    "    \n",
    "    #data_array.append(dict_values)\n",
    "    data_array.append(dict_values['utterance'][1:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_data(data_array):\n",
    "    for utterance in data_array:\n",
    "        #apply some tokenization of each utterance\n",
    "        yield gensim.utils.simple_preprocess(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = list(retrieve_data(data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(utterances, size=300, window=10, min_count=2, workers=10, iter= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30326"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22218640, 30251270)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(utterances, total_examples=len(utterances), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets now the check the similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', 0.5045223236083984),\n",
       " ('tough', 0.4259261190891266),\n",
       " ('beginner', 0.3719980716705322),\n",
       " ('quick', 0.3636906147003174),\n",
       " ('rough', 0.362427681684494),\n",
       " ('chipper', 0.3558504581451416),\n",
       " ('smart', 0.3500877022743225),\n",
       " ('nice', 0.34913361072540283),\n",
       " ('lucky', 0.34018972516059875),\n",
       " ('clever', 0.3382002115249634)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='good',topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a word embedding from a pretrained word embedding such as google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reason for separating the trained vectors into KeyedVectors is that if you don’t need the full model state any more (don’t need to continue training)\n",
    "googl_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Word2Vec(utterances,size=300,window=10, min_count= 2, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30326"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model3.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francisdamachi/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "total_examples = model3.corpus_count\n",
    "google_vocab = list(googl_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.build_vocab([google_vocab], update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30326"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model3.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.intersect_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True, lockf=1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22218367, 30251270)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.train(utterances,total_examples=len(utterances), epochs = model3.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"wordvec_from_pretrained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.wv.save(\"wordvec_from_pretrained_model_vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_size = len(model3.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = np.zeros((max_size,model3.trainables.layer1_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.tsv\",'w+') as file_metadata:\n",
    "    for i,word in enumerate(model3.wv.index2word[:]):\n",
    "        w2v[i] = model3.wv[word]\n",
    "        file_metadata.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.65494841e-01,  7.94879913e-01,  5.16691506e-01, ...,\n",
       "         3.32302094e-04,  4.19694543e-01,  6.39392316e-01],\n",
       "       [-3.50675792e-01,  5.46539962e-01,  1.80310094e+00, ...,\n",
       "         1.13130677e+00,  7.12191686e-02, -6.13567650e-01],\n",
       "       [-4.86572176e-01,  1.24483027e-01,  1.95161760e+00, ...,\n",
       "        -7.97282100e-01, -2.88278282e-01, -4.87563998e-01],\n",
       "       ...,\n",
       "       [-8.84071067e-02,  9.88474488e-03, -6.01203367e-03, ...,\n",
       "        -5.69259096e-03,  2.21646484e-02, -1.79266959e-01],\n",
       "       [ 7.37095550e-02, -7.65446872e-02, -3.03474814e-01, ...,\n",
       "        -9.06900782e-03, -5.76125570e-02,  3.81703228e-01],\n",
       "       [ 1.62402451e-01, -8.63411725e-02, -5.71385771e-03, ...,\n",
       "         5.73954545e-02,  9.82717350e-02, -1.89005882e-01]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 2d tensor which holds the embdeings\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.Variable(w2v, trainable=False, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(path, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = projector.ProjectorConfig()\n",
    "embed = config.embeddings.add()\n",
    "embed.tensor_name = 'embedding'\n",
    "embed.metadata_path = 'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorboard/model.ckpt-30326'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "saver.save(sess, path+'/model.ckpt', global_step=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
